# Extraction Adaptative de Features - Diagrammes & Infographies

Pipeline Computer Vision avec **extraction adaptative** pour analyser automatiquement diffÃ©rents types d'images (pie charts, network graphs, flowcharts, infographics, etc.) et extraire des features pertinentes selon le type dÃ©tectÃ©.

---

## Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [MÃ©thodologie CV](#mÃ©thodologie-cv)
- [Installation](#installation)
- [Scripts disponibles](#scripts-disponibles)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [RÃ©sultats](#rÃ©sultats)

---

## Vue d'ensemble

### Approche Adaptative

Ce projet utilise une approche **adaptative** qui:

1. **Classifie automatiquement** le type d'image (pie chart, network graph, flowchart, etc.)
2. **Extrait des features spÃ©cifiques** selon le type dÃ©tectÃ©
3. **GÃ©nÃ¨re des descriptions enrichies** adaptÃ©es au contexte

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Auto â”‚  â† DÃ©tection du type
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ PIE CHART â†’ segments, angles, distribution
       â”œâ”€â”€â”€ NETWORK â†’ nodes, edges, centralitÃ©
       â”œâ”€â”€â”€ FLOWCHART â†’ Ã©tapes, niveaux, flow
       â”œâ”€â”€â”€ INFOGRAPHIC â†’ sections, layout
       â””â”€â”€â”€ ...
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Features Adaptatives â”‚  â† Extraction spÃ©cialisÃ©e
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Avantages

âœ“ **Pertinence**: Extraction adaptÃ©e Ã  chaque type d'image
âœ“ **Richesse**: Plus de features spÃ©cifiques extraites (+200% vs approche uniforme)
âœ“ **QualitÃ©**: Descriptions prÃ©cises et contextualisÃ©es
âœ“ **FlexibilitÃ©**: Facile d'ajouter de nouveaux types

---

## MÃ©thodologie CV

### Concepts Computer Vision utilisÃ©s

| Concept | Utilisation | OÃ¹ |
|---------|-------------|-----|
| **Grayscale Conversion** | Normalisation des images couleur | `preprocessing.py` |
| **CLAHE** | AmÃ©lioration de contraste adaptatif | `preprocessing.py` |
| **Bilateral Filter** | Lissage prÃ©servant les contours | `preprocessing.py` |
| **Canny Edge Detection** | DÃ©tection de contours | `image_classifier.py` |
| **Hough Transform** | DÃ©tection de cercles et lignes | `image_classifier.py` |
| **Connected Components** | Segmentation en rÃ©gions | `image_classifier.py` |
| **Otsu Thresholding** | Binarisation automatique | `preprocessing.py` |
| **Contour Analysis** | Analyse de formes | `adaptive_extractor.py` |
| **Morphological Ops** | Nettoyage et structuration | `preprocessing.py` |
| **Color Entropy** | Analyse de diversitÃ© couleur | `adaptive_extractor.py` |

### Pipeline dÃ©taillÃ©

```
1. PREPROCESSING (preprocessing.py)
   â”œâ”€ Grayscale conversion
   â”œâ”€ CLAHE (Contrast Limited Adaptive Histogram Equalization)
   â”œâ”€ Bilateral filtering
   â””â”€ Otsu thresholding

2. CLASSIFICATION (image_classifier.py)
   â”œâ”€ Hough Circle Detection â†’ Pie charts
   â”œâ”€ Hough Line Detection â†’ Flowcharts
   â”œâ”€ Connected Components â†’ Network graphs
   â”œâ”€ Edge density analysis
   â””â”€ â†’ Type dÃ©tectÃ© + confidence

3. EXTRACTION ADAPTATIVE (adaptive_extractor.py)
   â”œâ”€ Features universelles:
   â”‚  â”œâ”€ Visual complexity (edge density)
   â”‚  â”œâ”€ Color entropy
   â”‚  â”œâ”€ Text density
   â”‚  â””â”€ Spatial layout (grid/radial/hierarchical)
   â”‚
   â””â”€ Features spÃ©cifiques au type:
      â”œâ”€ PIE CHART: segments, angles, distribution
      â”œâ”€ NETWORK: nodes, edges, clustering
      â”œâ”€ FLOWCHART: steps, levels, branching
      â”œâ”€ INFOGRAPHIC: sections, visual elements
      â””â”€ ...

4. ENRICHISSEMENT
   â””â”€ GÃ©nÃ©ration de description contextuelle
```

---

## Installation

### PrÃ©requis
- Python 3.8+
- pip
- ~10 GB d'espace disque (pour le dataset)

### Setup

```bash
# Cloner le repository
cd traitement_data

# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer l'environnement
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### DÃ©pendances principales
- `opencv-python` - Computer Vision
- `numpy`, `pandas` - Traitement de donnÃ©es
- `matplotlib` - Visualisations
- `scikit-image` - Traitement d'images
- `tqdm` - Barres de progression

---

## Scripts disponibles

### 1. **`demo_adaptive_extraction.py`** - DÃ©monstration interactive

DÃ©montre l'extraction adaptative sur un Ã©chantillon d'images.

**Utilisation**:
```bash
python demo_adaptive_extraction.py        # 10 images par dÃ©faut
python demo_adaptive_extraction.py 20     # 20 images
```

**DurÃ©e**: ~1-2 minutes

**Sorties**:
- `outputs/results/adaptive_extraction.csv` - Features extraites
- `outputs/visualizations/adaptive_extraction_demo.png` - Visualisation

**Ce que Ã§a montre**:
- Classification automatique de chaque image
- Features spÃ©cifiques extraites selon le type
- Comparaison adaptative vs baseline
- Distribution des types dans l'Ã©chantillon

**Exemple de sortie**:
```
======================================================================
Image 0
======================================================================

 TYPE DÃ‰TECTÃ‰: NETWORK_GRAPH
   Confidence: 85.3%

 FEATURES UNIVERSELLES:
   Visual Complexity: 0.234
   Color Entropy: 2.456
   Text Density: 0.123
   Layout: hierarchical

 FEATURES SPÃ‰CIFIQUES AU TYPE:
   node_count: 12
   edge_count: 18
   clustering_coefficient: 0.456
   avg_degree: 3.0

 DESCRIPTION ENRICHIE:
   Network graph with 12 nodes and 18 edges, hierarchical layout, moderate density

 CAPTION ENRICHI:
   A diagram showing the relationship... [Visual Analysis: Network graph with 12 nodes...]
```

---

### 2. **`process_full_dataset.py`** - Traitement complet du dataset

Traite **tout le dataset** avec extraction adaptative et gÃ©nÃ¨re un CSV complet.

**Utilisation**:
```bash
# Traitement complet
python process_full_dataset.py

# Reprendre aprÃ¨s interruption
python process_full_dataset.py --resume

# DÃ©marrer Ã  un index spÃ©cifique
python process_full_dataset.py 1000
```

**DurÃ©e**: 2-4 heures (selon taille du dataset et machine)

**Sorties**:
- `outputs/results/full_dataset_adaptive.csv` - RÃ©sultats complets
- `outputs/results/processing_errors.csv` - Erreurs rencontrÃ©es
- `outputs/results/full_dataset_adaptive_temp.csv` - Sauvegardes intermÃ©diaires

**FonctionnalitÃ©s**:
- âœ“ Sauvegarde intermÃ©diaire tous les 500 images
- âœ“ Reprise possible aprÃ¨s interruption
- âœ“ Barre de progression avec ETA
- âœ“ Gestion des erreurs
- âœ“ Statistiques en temps rÃ©el

**Exemple de sortie**:
```
================================================================================
TRAITEMENT COMPLET DU DATASET - EXTRACTION ADAPTATIVE
================================================================================

[1/4] Chargement du dataset...
Dataset chargÃ©: 5000 images

[2/4] DÃ©marrage du traitement...

[3/4] Traitement de 5000 images...
Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [2:15:32<00:00, 1.64s/it]

[4/4] Sauvegarde finale...
Images traitÃ©es avec succÃ¨s: 4987 / 5000
Erreurs: 13

âœ“ RÃ©sultats sauvegardÃ©s: outputs/results/full_dataset_adaptive.csv

================================================================================
RÃ‰SUMÃ‰ DU TRAITEMENT
================================================================================

ğŸ“Š DISTRIBUTION DES TYPES (4987 images):
   network_graph       : 1234 (24.7%)
   pie_chart          :  892 (17.9%)
   flowchart          :  756 (15.2%)
   infographic        :  623 (12.5%)
   bar_chart          :  489 (9.8%)
   other              :  993 (19.9%)

ğŸ¯ CONFIDENCE MOYENNE: 78.3%
   Min: 45.2%
   Max: 98.7%

â± Temps total: 135.5 minutes
   Vitesse moyenne: 0.6 images/seconde
```

---

## Utilisation

### Workflow recommandÃ©

#### 1. DÃ©couverte (5 minutes)
```bash
# Tester l'extraction adaptative sur quelques images
python demo_adaptive_extraction.py 10
```

â†’ Voir comment le systÃ¨me s'adapte aux diffÃ©rents types

#### 2. Traitement complet (2-4 heures)
```bash
# Traiter tout le dataset
python process_full_dataset.py
```

â†’ GÃ©nÃ©rer le CSV complet avec toutes les features

#### 3. Analyse des rÃ©sultats
```python
import pandas as pd

# Charger les rÃ©sultats
df = pd.read_csv('outputs/results/full_dataset_adaptive.csv')

# Analyser la distribution des types
print(df['diagram_type'].value_counts())

# Features par type
for dtype in df['diagram_type'].unique():
    subset = df[df['diagram_type'] == dtype]
    print(f"\n{dtype}:")
    print(subset.filter(like='specific_').columns.tolist())

# Statistiques
print(df[['visual_complexity', 'color_entropy', 'text_density']].describe())
```

---

## Structure du projet

```
traitement_data/
â”œâ”€â”€ README.md                           # Ce fichier
â”œâ”€â”€ METHODOLOGY_ADAPTIVE_CV.md          # MÃ©thodologie dÃ©taillÃ©e
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”‚
â”œâ”€â”€ demo_adaptive_extraction.py         # â­ DÃ©mo interactive
â”œâ”€â”€ process_full_dataset.py             # â­ Traitement complet
â”‚
â”œâ”€â”€ src/                                # Code source
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                        # Utilitaires (chargement images, etc.)
â”‚   â”œâ”€â”€ preprocessing.py                # Preprocessing CV (CLAHE, bilateral, etc.)
â”‚   â”œâ”€â”€ image_classifier.py             # ğŸ”‘ Classification automatique du type
â”‚   â””â”€â”€ adaptive_extractor.py           # ğŸ”‘ Extraction adaptative
â”‚
â”œâ”€â”€ outputs/                            # RÃ©sultats gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ adaptive_extraction.csv     # DÃ©mo
â”‚   â”‚   â””â”€â”€ full_dataset_adaptive.csv   # Dataset complet
â”‚   â””â”€â”€ visualizations/
â”‚       â””â”€â”€ adaptive_extraction_demo.png
â”‚
â””â”€â”€ legacy/                             # Ancienne approche (archivÃ©e)
    â””â”€â”€ old_pipeline/
        â”œâ”€â”€ README_LEGACY.md            # Documentation legacy
        â”œâ”€â”€ test_pipeline.py
        â”œâ”€â”€ batch_analysis.py
        â””â”€â”€ src/
            â”œâ”€â”€ detection.py
            â”œâ”€â”€ segmentation.py
            â””â”€â”€ ...
```

### Modules principaux

#### `src/preprocessing.py`
Preprocessing des images avec techniques CV classiques.

```python
from src.preprocessing import ImagePreprocessor

preprocessor = ImagePreprocessor(target_size=(800, 800))
result = preprocessor.preprocess(
    image,
    grayscale=True,
    enhance_contrast_method='clahe',
    denoise_method='bilateral'
)
```

#### `src/image_classifier.py`
Classification automatique du type d'image.

```python
from src.image_classifier import classify_diagram_type

diagram_type, confidence, metrics = classify_diagram_type(image)
# diagram_type: 'pie_chart', 'network_graph', 'flowchart', etc.
# confidence: 0.0 - 1.0
```

**MÃ©thodes de classification**:
- Hough Circle Detection â†’ Pie charts
- Hough Line Detection â†’ Flowcharts
- Connected Components â†’ Networks
- Edge density analysis
- Shape regularity

#### `src/adaptive_extractor.py`
Extraction de features adaptÃ©e au type dÃ©tectÃ©.

```python
from src.adaptive_extractor import extract_adaptive_features

features = extract_adaptive_features(img_processed, img_original)

# AccÃ¨s aux features
print(features.diagram_type)           # Type dÃ©tectÃ©
print(features.type_confidence)        # Confiance (0-1)
print(features.visual_complexity)      # ComplexitÃ© visuelle
print(features.color_entropy)          # Entropie couleur
print(features.text_density)           # DensitÃ© de texte
print(features.spatial_layout)         # Layout (grid/radial/hierarchical)
print(features.specific_features)      # Dict de features spÃ©cifiques au type
print(features.description_enrichment) # Description enrichie
```

---

## RÃ©sultats

### Format du CSV gÃ©nÃ©rÃ©

Le fichier `full_dataset_adaptive.csv` contient:

| Colonne | Description | Type |
|---------|-------------|------|
| `image_idx` | Index de l'image dans le dataset | int |
| `diagram_type` | Type dÃ©tectÃ© | str |
| `type_confidence` | Confiance de classification | float (0-1) |
| `visual_complexity` | ComplexitÃ© visuelle (edge density) | float |
| `color_entropy` | Entropie de couleur | float |
| `text_density` | DensitÃ© de texte estimÃ©e | float |
| `spatial_layout` | Type de layout (grid/radial/hierarchical) | str |
| `enrichment` | Description enrichie | str |
| `specific_*` | Features spÃ©cifiques au type | varies |
| `original_caption` | Caption original du dataset | str |
| `enriched_caption` | Caption + analyse visuelle | str |

### Exemples de features spÃ©cifiques

**PIE CHART**:
- `specific_segment_count`: Nombre de segments
- `specific_largest_segment_angle`: Angle du plus grand segment
- `specific_distribution_entropy`: UniformitÃ© de la distribution

**NETWORK GRAPH**:
- `specific_node_count`: Nombre de nÅ“uds
- `specific_edge_count`: Nombre d'arÃªtes
- `specific_clustering_coefficient`: Coefficient de clustering
- `specific_avg_degree`: DegrÃ© moyen

**FLOWCHART**:
- `specific_step_count`: Nombre d'Ã©tapes
- `specific_vertical_levels`: Niveaux verticaux
- `specific_branching_factor`: Facteur de branchement

**INFOGRAPHIC**:
- `specific_section_count`: Nombre de sections
- `specific_icon_count`: Nombre d'icÃ´nes/symboles
- `specific_color_scheme_diversity`: DiversitÃ© de la palette

---

## Comparaison: Adaptative vs Uniforme

| Aspect | Approche Uniforme (Legacy) | Approche Adaptative (Actuelle) |
|--------|---------------------------|-------------------------------|
| **Traitement** | Identique pour toutes les images | AdaptÃ© au type dÃ©tectÃ© |
| **Features extraites** | ~5 features gÃ©nÃ©riques | ~8-15 features (5 universelles + spÃ©cifiques) |
| **Pertinence** | Faible pour types variÃ©s | Haute pour tous types |
| **Descriptions** | GÃ©nÃ©riques | ContextualisÃ©es |
| **Richesse** | Baseline | +200% d'information |
| **ComplexitÃ©** | Simple | Modulaire |

**Gain mesurÃ©**: L'approche adaptative extrait **2-3x plus d'information pertinente** par image.

---

## Ancienne approche (Legacy)

L'ancienne approche pipeline uniforme est archivÃ©e dans `legacy/old_pipeline/`.

**Pourquoi archivÃ©e?**
- Traitement uniforme peu adaptÃ© Ã  des images variÃ©es
- Extraction sous-optimale pour 70% du dataset
- RemplacÃ©e par l'approche adaptative plus performante

**Quand utiliser legacy?**
- Dataset homogÃ¨ne (uniquement network graphs)
- Apprentissage des concepts CV de base
- Baseline pour comparaison

ğŸ“š Voir [legacy/old_pipeline/README_LEGACY.md](legacy/old_pipeline/README_LEGACY.md) pour plus de dÃ©tails.

---

## MÃ©thodologie complÃ¨te

Pour une explication dÃ©taillÃ©e de la mÃ©thodologie CV, voir:
ğŸ“– [METHODOLOGY_ADAPTIVE_CV.md](METHODOLOGY_ADAPTIVE_CV.md)

---

## Troubleshooting

### Erreur: "Module not found"
```bash
# VÃ©rifier que le venv est activÃ©
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# RÃ©installer les dÃ©pendances
pip install -r requirements.txt
```

### Erreur: "Dataset download fails"
- VÃ©rifier la connexion internet
- Le dataset fait plusieurs GB, attendre quelques minutes
- VÃ©rifier l'espace disque disponible

### Erreur: "Out of memory"
```bash
# RÃ©duire le nombre d'images
python demo_adaptive_extraction.py 5

# Ou traiter par petits batches
python process_full_dataset.py  # Utilise dÃ©jÃ  des sauvegardes intermÃ©diaires
```

### Reprise aprÃ¨s interruption
```bash
# Le script dÃ©tecte automatiquement le fichier temporaire
python process_full_dataset.py --resume
```

---

## Performance

### Benchmarks (machine typique)

| TÃ¢che | Temps | Vitesse |
|-------|-------|---------|
| Classification d'une image | ~50ms | 20 img/s |
| Extraction complÃ¨te (1 image) | ~200ms | 5 img/s |
| Traitement 10 images | ~2s | - |
| Traitement 1000 images | ~5 min | 3.3 img/s |
| Traitement dataset complet (5000) | ~2.5h | 0.6 img/s |

*Note: Vitesse dÃ©pend de la complexitÃ© des images et de la machine*

---

## Contribution & Extensions

### Ajouter un nouveau type de diagramme

1. **Ajouter le type dans `image_classifier.py`**:
```python
class DiagramType:
    # ...
    NEW_TYPE = "new_type"
```

2. **CrÃ©er une fonction de dÃ©tection**:
```python
def detect_new_type(img, metrics):
    # Logique de dÃ©tection
    score = ...
    return score
```

3. **Ajouter l'extracteur dans `adaptive_extractor.py`**:
```python
def extract_new_type_features(img_gray, img_color):
    return {
        'feature1': value1,
        'feature2': value2,
        # ...
    }
```

4. **Mettre Ã  jour le dispatcher**:
```python
if diagram_type == DiagramType.NEW_TYPE:
    specific = extract_new_type_features(img_gray, img_color)
```

---

## Licence

Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique.

---

## Contact & Support

Pour toute question ou problÃ¨me:
1. VÃ©rifier la [documentation legacy](legacy/old_pipeline/README_LEGACY.md)
2. Consulter [METHODOLOGY_ADAPTIVE_CV.md](METHODOLOGY_ADAPTIVE_CV.md)
3. Ouvrir une issue sur le repository

---

**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2025
